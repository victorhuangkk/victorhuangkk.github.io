---
layout: post
title: TD Proposal
tags: [other]
comments: true
---


## Summary

In this internship, I am trying to provide end-to-end machine learning solutions to help traders improve their performance over time. Technical trading exist for a long time, however, human beings may not be able to conceive all the information as fast as machine. Simultaneously, human might be biased towards what they believe. So, quantitative models have been adopted in the finance world, to help traders

## Time Series Forecasting
Time series is a long lasting field in statistical research. From auto regressive to moving average. Then, ARIMA and VAR came out. The later one is able to incorporate multiple features all together. That is also the main drawback of traditional time series models, which cannot utilize contextual features. In this project, I  

## Natural Language Processing
Natural language processing (NLP) is two of the most widely used machine learning technics, the other one is computer vision. Considering all the data we have on hand now, they are all numerical. In some sense, numerical data is biased and very limited. Deep learning is powerful when you give it enough volume of data. Considering the well known AlexNet, they applied deep neural network on image data and dwarfed all the other approaches. Reasons are they have 1.2 million high resolution images and train a model with 60 million parameters. And supremacy of deep learning is set on top of big data. So, in this part, our purpose is to extract as much information as possible from text data.

My plan is to build multiple text related features based on text data, and add those extra information to our time series models. To make the example more concrete, let's focus on annually company report. Stakeholders would cover multiple topics, and their wording have sentiment, and numerical data mentioned in the report are all available information. Besides 10K, 10Q reports, we may explore social network as well, including facebook, twitter and reddit. After collecting all useful text data, Bloomberg ID and time would be used as the unique identifier for each record. Then, I will process and organize the data, conduct LDA(Latent Dirichelet Allocation) to do topic modeling, and BERT (the Google SOTA NLP model) to conduct sentiment analysis and further feature engineering. Basically, the plan is to embed more predictors to the time series model to unleash deep learning model.  


## Reinforcement Learning Trading
The final goal of trading is to generate profit and alleviate risk. We are the trading team, such that passive investment (portfolio optimization) may not be the good direction. In the recent ten years, an increasingly amount of efforts have been devoted to apply Reinforcement Learning to quantitative trading. In general, there are a few key components in reinforcement learning which match their counterparts in finance greatly. For example, environment is term in reinforcement learning, corresponding to all the unknown information. And in finance, this term naturally matches with the generic financial market. And to make this design doc project specific, I would skip the theoretical explanations and jump directly to model selection and execution plan.

To complement this project in a reasonable time frame, I choose to use a relatively simple reinforcement technic, Thompson Sampling, which was developed to solve multi arms bandit (MAB) problem. MAB's scenario is that you have multiple slot machines in front of you, each of them have different odds to win. Your task is to maximize your profit in a limited time. And the key pain points in this problem is to balance exploration and exploitation. By having trading odds given by the time series model, traders know they have to long/short certain assets. However, how many shares should they trade; should they hold or wait? All of these questions could be answered by the reinforcement learning model. Or, at least, help traders to function more effectively.

The plan is to backtest multiple strategies generated by the time series model by allocating different weights to autoregressive factor, natural language factor and potentially other factors. Each strategy is a "slot machine" in our application and our goal is to modify each strategy and find out the strategy with highest return.  


## Visualization and Dashboarding
For presentation purposes, a python dashboard (written in Dash) would be provided to provide data insights. Compared with static slides, end users would be able to pull data based on their interest. And for development purposes, this dashboard is useful for debugging purposes. Technical details would be skipped in this design doc, but I would love to list out some keys features of this dashboard.

1. It is multi-tab, enable user to easily search for information that they have interest to.
2. It is Dash native. As little dependencies are used as possible to avoid confusion.
3. Multi sessions are enabled. Based on the current design, it should support at most ten users to interact with the dashboard simultaneously. User's data are isolated and would not be shared cross session.

For further implementation details, please refer to this repo on my deepgreen folder.
